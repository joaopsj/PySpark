{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1bBWi7AlGFT2dk_9sjCrwlphg8zYkxQwY",
      "authorship_tag": "ABX9TyMXw6HCHgB6RnknhIQAIalm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaopsj/PySpark/blob/main/1fst_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Configuração de ambiente**"
      ],
      "metadata": {
        "id": "ICoE8eFy72Uu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-Wde9ZE7X4e"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.2.3/spark-3.2.3-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "cjnF9ku984Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf spark-3.2.3-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "p_Wsw38W8901"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "80h675eX9IgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark"
      ],
      "metadata": {
        "id": "y2Mf4NPj9Let"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.3-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "h54l4MXt8mRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Importação dos pacotes e datasets**\n",
        "####**Testar se os pacotes foram instalados**\n",
        "####**Importação de dados**"
      ],
      "metadata": {
        "id": "6eVOiUT-Dv1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "sDzRnAQdNqhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "AOrQo4XKNz_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = spark.read.csv('/content/sample_data/california_housing_test.csv',inferSchema=True, header =True)"
      ],
      "metadata": {
        "id": "qbWtx83IN1n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.printSchema()"
      ],
      "metadata": {
        "id": "mj6SZC3zN44u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "DxFpa-TAN8U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "NEAsE7uYN-dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. Convertendo Pandas DataFrame em Spark DataFrame**"
      ],
      "metadata": {
        "id": "q0BLW62aOdWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession     "
      ],
      "metadata": {
        "id": "Uo4bGmC_O0LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "media = 0\n",
        "desvio_padrao=0.1 \n",
        "pd_temporario = pd.DataFrame(np.random.normal(media,desvio_padrao,100))"
      ],
      "metadata": {
        "id": "hAyOdFuLSsGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark_temporario = spark.createDataFrame(pd_temporario)\n",
        "spark_temporario.createOrReplaceTempView(\"nova_tabela_temporaria\")\n",
        "print(spark.catalog.listTables())         \n"
      ],
      "metadata": {
        "id": "ejH8D_1PPLAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "2-VLQDfxTeML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. Práticas de MapReduce**"
      ],
      "metadata": {
        "id": "yMS4xdEkGzD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Exemplo 1**"
      ],
      "metadata": {
        "id": "FyG8_efBPuiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "A2Ah3O2rG_Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "_aevxRtjFtMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([10, 300, 115, 18, 46])"
      ],
      "metadata": {
        "id": "VfHsotTgGwoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert = spark.sparkContext.parallelize(data)"
      ],
      "metadata": {
        "id": "fzJ8U5m9IAyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapa = convert.map(lambda x : x**2+x)"
      ],
      "metadata": {
        "id": "6sy33FIvF6H8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapa.collect()"
      ],
      "metadata": {
        "id": "nb7vIAh5IyLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Exemplo 2**"
      ],
      "metadata": {
        "id": "T1WjFUFgP1dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.parallelize([\"dist\",\"equal\",\"dist\",\"forms\",\"locals\",\"equal\",\"hist\"])"
      ],
      "metadata": {
        "id": "vUYZEfgjP4YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = lambda x : (x,1)"
      ],
      "metadata": {
        "id": "3CwE6kgBQYiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import add\n",
        "mapa = rdd.map(f).reduceByKey(add).collect()"
      ],
      "metadata": {
        "id": "QnlyVx_QQuUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (x, y) in mapa:\n",
        "  print(\"{}: {}\".format(x, y))"
      ],
      "metadata": {
        "id": "YJOGltSmQ1eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "Bx7k3bkPf6BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exemplo 3**"
      ],
      "metadata": {
        "id": "j_SidnwmZ3UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "v6Ar58L7Z8Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "zfz4ISDOhjVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista = [15, 25, 60, 80, 120, 15]\n",
        "lista_rdd = spark.sparkContext.parallelize(lista)"
      ],
      "metadata": {
        "id": "xqpEuJScgAZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_rdd.count()"
      ],
      "metadata": {
        "id": "Xz7qgwKpgNb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = lambda numero: (numero, numero*12)"
      ],
      "metadata": {
        "id": "NZ_IovUljZb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_rdd.flatMap(f).collect()"
      ],
      "metadata": {
        "id": "fih7gTy-j7SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_rdd.map(f).collect()"
      ],
      "metadata": {
        "id": "X90d9BvmkI-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "_nY52ITckO37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}