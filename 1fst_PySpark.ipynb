{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1bBWi7AlGFT2dk_9sjCrwlphg8zYkxQwY",
      "authorship_tag": "ABX9TyO5U5LEePwAwg7NSznb5XYp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaopsj/PySpark/blob/main/1fst_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Configuração de ambiente**"
      ],
      "metadata": {
        "id": "ICoE8eFy72Uu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-Wde9ZE7X4e"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.2.3/spark-3.2.3-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "cjnF9ku984Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf spark-3.2.3-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "p_Wsw38W8901"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "80h675eX9IgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark"
      ],
      "metadata": {
        "id": "y2Mf4NPj9Let"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.3-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "h54l4MXt8mRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Importação dos pacotes e datasets**\n",
        "####**Testar se os pacotes foram instalados**\n",
        "####**Importação de dados**"
      ],
      "metadata": {
        "id": "6eVOiUT-Dv1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "sDzRnAQdNqhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "AOrQo4XKNz_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = spark.read.csv('/content/sample_data/california_housing_test.csv',inferSchema=True, header =True)"
      ],
      "metadata": {
        "id": "qbWtx83IN1n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj6SZC3zN44u",
        "outputId": "16d98823-fb65-4fb0-d27b-ec07551e672a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxFpa-TAN8U7",
        "outputId": "fe7d8e4e-8bd1-4951-e334-44ef2cf18cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(longitude=-122.05, latitude=37.37, housing_median_age=27.0, total_rooms=3885.0, total_bedrooms=661.0, population=1537.0, households=606.0, median_income=6.6085, median_house_value=344700.0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "NEAsE7uYN-dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. Convertendo Pandas DataFrame em Spark DataFrame**"
      ],
      "metadata": {
        "id": "q0BLW62aOdWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession     "
      ],
      "metadata": {
        "id": "Uo4bGmC_O0LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "media = 0\n",
        "desvio_padrao=0.1 \n",
        "pd_temporario = pd.DataFrame(np.random.normal(media,desvio_padrao,100))"
      ],
      "metadata": {
        "id": "hAyOdFuLSsGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark_temporario = spark.createDataFrame(pd_temporario)\n",
        "spark_temporario.createOrReplaceTempView(\"nova_tabela_temporaria\")\n",
        "print(spark.catalog.listTables())         \n"
      ],
      "metadata": {
        "id": "ejH8D_1PPLAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "2-VLQDfxTeML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. Práticas de MapReduce**"
      ],
      "metadata": {
        "id": "yMS4xdEkGzD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Exemplo 1**"
      ],
      "metadata": {
        "id": "FyG8_efBPuiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "A2Ah3O2rG_Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "_aevxRtjFtMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([10, 300, 115, 18, 46])"
      ],
      "metadata": {
        "id": "VfHsotTgGwoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert = spark.sparkContext.parallelize(data)"
      ],
      "metadata": {
        "id": "fzJ8U5m9IAyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapa = convert.map(lambda x : x**2+x)"
      ],
      "metadata": {
        "id": "6sy33FIvF6H8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapa.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb7vIAh5IyLn",
        "outputId": "44e3c774-4c27-4405-c5c1-79dcaf553473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[110, 90300, 13340, 342, 2162]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Exemplo 2**"
      ],
      "metadata": {
        "id": "T1WjFUFgP1dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.parallelize([\"dist\",\"equal\",\"dist\",\"forms\",\"locals\",\"equal\",\"hist\"])"
      ],
      "metadata": {
        "id": "vUYZEfgjP4YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = lambda x : (x,1)"
      ],
      "metadata": {
        "id": "3CwE6kgBQYiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import add\n",
        "mapa = rdd.map(f).reduceByKey(add).collect()"
      ],
      "metadata": {
        "id": "QnlyVx_QQuUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (x, y) in mapa:\n",
        "  print(\"{}: {}\".format(x, y))"
      ],
      "metadata": {
        "id": "YJOGltSmQ1eP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad2f99eb-55d1-4165-f139-695fe2323e10"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dist: 2\n",
            "equal: 2\n",
            "locals: 1\n",
            "hist: 1\n",
            "forms: 1\n"
          ]
        }
      ]
    }
  ]
}